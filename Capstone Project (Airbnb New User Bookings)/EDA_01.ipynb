{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_users = pd.read_csv('Data/train_users_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_users['gender'] = train_users['gender'].replace('-unknown-', np.nan)\n",
    "train_users['first_browser'] = train_users['first_browser'].replace('-unknown-', np.nan)\n",
    "train_users['age'] = train_users['age'].apply(lambda x: np.nan if x > 120 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = train_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>action</th>\n",
       "      <th>action_type</th>\n",
       "      <th>action_detail</th>\n",
       "      <th>device_type</th>\n",
       "      <th>secs_elapsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d1mm9tcy42</td>\n",
       "      <td>lookup</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Windows Desktop</td>\n",
       "      <td>319.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d1mm9tcy42</td>\n",
       "      <td>search_results</td>\n",
       "      <td>click</td>\n",
       "      <td>view_search_results</td>\n",
       "      <td>Windows Desktop</td>\n",
       "      <td>67753.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d1mm9tcy42</td>\n",
       "      <td>lookup</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Windows Desktop</td>\n",
       "      <td>301.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d1mm9tcy42</td>\n",
       "      <td>search_results</td>\n",
       "      <td>click</td>\n",
       "      <td>view_search_results</td>\n",
       "      <td>Windows Desktop</td>\n",
       "      <td>22141.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d1mm9tcy42</td>\n",
       "      <td>lookup</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Windows Desktop</td>\n",
       "      <td>435.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>d1mm9tcy42</td>\n",
       "      <td>search_results</td>\n",
       "      <td>click</td>\n",
       "      <td>view_search_results</td>\n",
       "      <td>Windows Desktop</td>\n",
       "      <td>7703.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>d1mm9tcy42</td>\n",
       "      <td>lookup</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Windows Desktop</td>\n",
       "      <td>115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>d1mm9tcy42</td>\n",
       "      <td>personalize</td>\n",
       "      <td>data</td>\n",
       "      <td>wishlist_content_update</td>\n",
       "      <td>Windows Desktop</td>\n",
       "      <td>831.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>d1mm9tcy42</td>\n",
       "      <td>index</td>\n",
       "      <td>view</td>\n",
       "      <td>view_search_results</td>\n",
       "      <td>Windows Desktop</td>\n",
       "      <td>20842.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>d1mm9tcy42</td>\n",
       "      <td>lookup</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Windows Desktop</td>\n",
       "      <td>683.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>d1mm9tcy42</td>\n",
       "      <td>search_results</td>\n",
       "      <td>click</td>\n",
       "      <td>view_search_results</td>\n",
       "      <td>Windows Desktop</td>\n",
       "      <td>59274.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>d1mm9tcy42</td>\n",
       "      <td>lookup</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Windows Desktop</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>d1mm9tcy42</td>\n",
       "      <td>personalize</td>\n",
       "      <td>data</td>\n",
       "      <td>wishlist_content_update</td>\n",
       "      <td>Windows Desktop</td>\n",
       "      <td>1399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>d1mm9tcy42</td>\n",
       "      <td>index</td>\n",
       "      <td>view</td>\n",
       "      <td>view_search_results</td>\n",
       "      <td>Windows Desktop</td>\n",
       "      <td>74886.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>d1mm9tcy42</td>\n",
       "      <td>similar_listings</td>\n",
       "      <td>data</td>\n",
       "      <td>similar_listings</td>\n",
       "      <td>Windows Desktop</td>\n",
       "      <td>255.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id            action action_type            action_detail  \\\n",
       "0   d1mm9tcy42            lookup         NaN                      NaN   \n",
       "1   d1mm9tcy42    search_results       click      view_search_results   \n",
       "2   d1mm9tcy42            lookup         NaN                      NaN   \n",
       "3   d1mm9tcy42    search_results       click      view_search_results   \n",
       "4   d1mm9tcy42            lookup         NaN                      NaN   \n",
       "5   d1mm9tcy42    search_results       click      view_search_results   \n",
       "6   d1mm9tcy42            lookup         NaN                      NaN   \n",
       "7   d1mm9tcy42       personalize        data  wishlist_content_update   \n",
       "8   d1mm9tcy42             index        view      view_search_results   \n",
       "9   d1mm9tcy42            lookup         NaN                      NaN   \n",
       "10  d1mm9tcy42    search_results       click      view_search_results   \n",
       "11  d1mm9tcy42            lookup         NaN                      NaN   \n",
       "12  d1mm9tcy42       personalize        data  wishlist_content_update   \n",
       "13  d1mm9tcy42             index        view      view_search_results   \n",
       "14  d1mm9tcy42  similar_listings        data         similar_listings   \n",
       "\n",
       "        device_type  secs_elapsed  \n",
       "0   Windows Desktop         319.0  \n",
       "1   Windows Desktop       67753.0  \n",
       "2   Windows Desktop         301.0  \n",
       "3   Windows Desktop       22141.0  \n",
       "4   Windows Desktop         435.0  \n",
       "5   Windows Desktop        7703.0  \n",
       "6   Windows Desktop         115.0  \n",
       "7   Windows Desktop         831.0  \n",
       "8   Windows Desktop       20842.0  \n",
       "9   Windows Desktop         683.0  \n",
       "10  Windows Desktop       59274.0  \n",
       "11  Windows Desktop          95.0  \n",
       "12  Windows Desktop        1399.0  \n",
       "13  Windows Desktop       74886.0  \n",
       "14  Windows Desktop         255.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session = pd.read_csv('data/sessions.csv')\n",
    "session.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Session Features\n",
    "The first feature I want to explore is the number of devices a user accesses the app through. My hunch is that if the user uses a lot of devices, it implies s/he travels very often and hence and would be likely to book an Airbnb. An additional hypothesis is that if the person travels a lot, s/he must probably be a business traveler and hence would likely be inclined to book Airbnbs within the United States.\n",
    "\n",
    "The second feature I want is the total number of seconds the user has spent on Airbnb Sessions. It will be interesting to see how this correlates with out classes.\n",
    "\n",
    "The third feature is average seconds per session. My assumption is that if someone spends more time per sesion that implies the user is more likly to book.\n",
    "\n",
    "The fourth feature is total number of sessions. As with total seconds, this might indicate greater interest.\n",
    "\n",
    "The final feature I want to look at is number of short sessions. These are sessions less than 300 seconds long, it may be an indicator that the user didn't like the search results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def session_features(df):\n",
    "    df['total_seconds'] = df['id'].apply(lambda x: total_seconds[x] if x in total_seconds else 0)\n",
    "    df['average_seconds'] = df['id'].apply(lambda x: average_seconds[x] if x in average_seconds else 0)\n",
    "    df['total_sessions'] = df['id'].apply(lambda x: total_sessions[x] if x in total_sessions else 0)\n",
    "    df['distinct_sessions'] = df['id'].apply(lambda x: distinct_sessions[x] if x in distinct_sessions else 0)\n",
    "    df['num_short_sessions'] = df['id'].apply(lambda x: num_short_sessions[x] if x in num_short_sessions else 0)\n",
    "    df['num_long_sessions'] = df['id'].apply(lambda x: num_long_sessions[x] if x in num_long_sessions else 0)\n",
    "    df['num_devices'] = df['id'].apply(lambda x: num_devices[x] if x in num_devices else 0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This feature is creating flag for Mobile_Safari category in the feature 'first_browser'\n",
    "\n",
    "def browsers(df):\n",
    "    df['first_browser'] = df['first_browser'].apply(lambda x: \"Mobile_Safari\" if x == \"Mobile Safari\" else x)\n",
    "    major_browsers = ['Chrome', 'Safari', 'Firefox', 'IE', 'Mobile_Safari']\n",
    "    df['first_browser'] = df['first_browser'].apply(lambda x: 'Other' if x not in major_browsers else x)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This feature is creating flag for device type\n",
    "\n",
    "def classify_device(x):\n",
    "    if x.find('Desktop') != -1:\n",
    "        return 'Desktop'\n",
    "    elif x.find('Tablet') != -1 or x.find('iPad') != -1:\n",
    "        return 'Tablet'\n",
    "    elif x.find('Phone') != -1:\n",
    "        return 'Phone'\n",
    "    else:\n",
    "        return 'Unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def devices(df):\n",
    "    df['first_device_type'] = df['first_device_type'].apply(classify_device)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def affiliate_tracked(df):\n",
    "    df['first_affiliate_tracked'] = df['first_affiliate_tracked'].fillna('Unknown')\n",
    "    df['first_affiliate_tracked'] = df['first_affiliate_tracked'].apply(lambda x: 'Other' if x != 'Unknown' and x != 'untracked' else x)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def affiliate_provider(df):\n",
    "    df['affiliate_provider'] = df['affiliate_provider'].apply(lambda x: 'rest' if x not in ['direct', 'google', 'other'] else x)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def affiliate_channel(df):\n",
    "    df['affiliate_channel'] = df['affiliate_channel'].apply(lambda x: 'other' if x  not in ['direct', 'content'] else x)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def languages(df):\n",
    "    df['language'] = df['language'].apply(lambda x: 'foreign' if x != 'en' else x)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_booking(df):\n",
    "    df = df.drop('date_first_booking', axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def account_created(df):\n",
    "    df = df.drop('date_account_created', axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df):\n",
    "    df = session_features(df)\n",
    "    df = df.drop('age', axis=1)\n",
    "    df = browsers(df)\n",
    "    df = devices(df)\n",
    "    df = affiliate_tracked(df)\n",
    "    df = affiliate_provider(df)\n",
    "    df = affiliate_channel(df)\n",
    "    df = languages(df)\n",
    "    df['is_3'] = df['signup_flow'].apply(lambda x: 1 if x==3 else 0)\n",
    "    df = first_booking(df)\n",
    "    df = df.drop('timestamp_first_active', axis=1)\n",
    "    df = account_created(df)\n",
    "    df = df.set_index('id')\n",
    "    df = pd.get_dummies(df, prefix='is')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.043171e+07\n",
       "mean     1.940581e+04\n",
       "std      8.888424e+04\n",
       "min      0.000000e+00\n",
       "25%      2.290000e+02\n",
       "50%      1.147000e+03\n",
       "75%      8.444000e+03\n",
       "max      1.799977e+06\n",
       "Name: secs_elapsed, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore 'secs_elapsed'\n",
    "session['secs_elapsed'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136031"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(session[session['secs_elapsed'].isnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_secs = session['secs_elapsed'].median()\n",
    "session['secs_elapsed'] = session['secs_elapsed'].fillna(median_secs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.056774e+07\n",
       "mean     1.917078e+04\n",
       "std      8.833430e+04\n",
       "min      0.000000e+00\n",
       "25%      2.370000e+02\n",
       "50%      1.147000e+03\n",
       "75%      8.193000e+03\n",
       "max      1.799977e+06\n",
       "Name: secs_elapsed, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session['secs_elapsed'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>action</th>\n",
       "      <th>action_type</th>\n",
       "      <th>action_detail</th>\n",
       "      <th>device_type</th>\n",
       "      <th>secs_elapsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d1mm9tcy42</td>\n",
       "      <td>lookup</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Windows Desktop</td>\n",
       "      <td>319.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d1mm9tcy42</td>\n",
       "      <td>lookup</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Windows Desktop</td>\n",
       "      <td>301.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d1mm9tcy42</td>\n",
       "      <td>lookup</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Windows Desktop</td>\n",
       "      <td>435.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>d1mm9tcy42</td>\n",
       "      <td>lookup</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Windows Desktop</td>\n",
       "      <td>115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>d1mm9tcy42</td>\n",
       "      <td>lookup</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Windows Desktop</td>\n",
       "      <td>683.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id  action action_type action_detail      device_type  secs_elapsed\n",
       "0  d1mm9tcy42  lookup         NaN           NaN  Windows Desktop         319.0\n",
       "2  d1mm9tcy42  lookup         NaN           NaN  Windows Desktop         301.0\n",
       "4  d1mm9tcy42  lookup         NaN           NaN  Windows Desktop         435.0\n",
       "6  d1mm9tcy42  lookup         NaN           NaN  Windows Desktop         115.0\n",
       "9  d1mm9tcy42  lookup         NaN           NaN  Windows Desktop         683.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_action = session[(session['action_type'].isnull()) | (session['action_detail'].isnull()) | (session['action'].isnull()) ]\n",
    "null_action.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1205830, 6)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_action.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(null_action['action'].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "session['device_type'] = session['device_type'].replace('-unknown-', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total time spent by user\n",
    "total_seconds = session.groupby('user_id')['secs_elapsed'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average time spent by user\n",
    "average_seconds = session.groupby('user_id')['secs_elapsed'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total session for each user\n",
    "total_sessions = session.groupby('user_id')['action'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count of distinct session action taken by each user\n",
    "distinct_sessions = session.groupby('user_id')['action'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_short_sessions = session[session['secs_elapsed'] <= 300].groupby('user_id')['action'].count()\n",
    "num_long_sessions = session[session['secs_elapsed'] >= 2000].groupby('user_id')['action'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of different devices used by each user\n",
    "num_devices = session.groupby('user_id')['device_type'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aligning session data with user informations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = session_features(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                              0\n",
       "date_account_created            0\n",
       "timestamp_first_active          0\n",
       "date_first_booking         124543\n",
       "gender                      95688\n",
       "age                         88771\n",
       "signup_method                   0\n",
       "signup_flow                     0\n",
       "language                        0\n",
       "affiliate_channel               0\n",
       "affiliate_provider              0\n",
       "first_affiliate_tracked      6065\n",
       "signup_app                      0\n",
       "first_device_type               0\n",
       "first_browser               27266\n",
       "country_destination             0\n",
       "total_seconds                   0\n",
       "average_seconds                 0\n",
       "total_sessions                  0\n",
       "distinct_sessions               0\n",
       "num_short_sessions              0\n",
       "num_long_sessions               0\n",
       "num_devices                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop('age', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                              0\n",
       "date_account_created            0\n",
       "timestamp_first_active          0\n",
       "date_first_booking         124543\n",
       "gender                      95688\n",
       "signup_method                   0\n",
       "signup_flow                     0\n",
       "language                        0\n",
       "affiliate_channel               0\n",
       "affiliate_provider              0\n",
       "first_affiliate_tracked      6065\n",
       "signup_app                      0\n",
       "first_device_type               0\n",
       "first_browser               27266\n",
       "country_destination             0\n",
       "total_seconds                   0\n",
       "average_seconds                 0\n",
       "total_sessions                  0\n",
       "distinct_sessions               0\n",
       "num_short_sessions              0\n",
       "num_long_sessions               0\n",
       "num_devices                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = browsers(df_train)\n",
    "df_train = devices(df_train)\n",
    "df_train = affiliate_tracked(df_train)\n",
    "df_train = affiliate_provider(df_train)\n",
    "df_train = affiliate_channel(df_train)\n",
    "df_train = languages(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                              0\n",
       "date_account_created            0\n",
       "timestamp_first_active          0\n",
       "date_first_booking         124543\n",
       "gender                      95688\n",
       "signup_method                   0\n",
       "signup_flow                     0\n",
       "language                        0\n",
       "affiliate_channel               0\n",
       "affiliate_provider              0\n",
       "first_affiliate_tracked         0\n",
       "signup_app                      0\n",
       "first_device_type               0\n",
       "first_browser                   0\n",
       "country_destination             0\n",
       "total_seconds                   0\n",
       "average_seconds                 0\n",
       "total_sessions                  0\n",
       "distinct_sessions               0\n",
       "num_short_sessions              0\n",
       "num_long_sessions               0\n",
       "num_devices                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In our EDA section, we noticed that people with signup flow 3 had a disproportionate number of conversions. \n",
    "# Therefore, we will define an additional feature that identifies these users. We will also revert back our gender \n",
    "# feture by filling in the NaNs with Unknown since we deduced that it will lead to an improvement in prediction.\n",
    "\n",
    "df_train['is_3'] = df_train['signup_flow'].apply(lambda x: 1 if x==3 else 0)\n",
    "df_train['gender'] = df_train['gender'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will drop the first_bookings and the timsestamp features. This is because they do not add any value when \n",
    "# finally testing the model with the test set. All our test users have NaNs as first booking and the timestamp is of no \n",
    "# significance.\n",
    "\n",
    "df_train = first_booking(df_train)\n",
    "df_train = df_train.drop('timestamp_first_active', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally we will drop the accounts created feature as our training and test sets were separated in the middle of 2014. As a result, all test users registered only in 2014.\n",
    "df_train = account_created(df_train)\n",
    "df_train = df_train.set_index('id')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender                     0\n",
       "signup_method              0\n",
       "signup_flow                0\n",
       "language                   0\n",
       "affiliate_channel          0\n",
       "affiliate_provider         0\n",
       "first_affiliate_tracked    0\n",
       "signup_app                 0\n",
       "first_device_type          0\n",
       "first_browser              0\n",
       "country_destination        0\n",
       "total_seconds              0\n",
       "average_seconds            0\n",
       "total_sessions             0\n",
       "distinct_sessions          0\n",
       "num_short_sessions         0\n",
       "num_long_sessions          0\n",
       "num_devices                0\n",
       "is_3                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our dataset is now in a position to have one hot encoding performed on it. Let us now separate our X and y data.\n",
    "class_dict = {\n",
    "    'NDF': 0,\n",
    "    'US': 1,\n",
    "    'other': 2,\n",
    "    'FR': 3,\n",
    "    'CA': 4,\n",
    "    'GB': 5,\n",
    "    'ES': 6,\n",
    "    'IT': 7,\n",
    "    'PT': 8,\n",
    "    'NL': 9,\n",
    "    'DE': 10,\n",
    "    'AU': 11\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df_train.drop('country_destination', axis=1), df_train['country_destination'].apply(lambda x: class_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X, prefix='is')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(X, y, train_size=0.75, stratify=y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Machine Learning\n",
    "The next step is to build a classifier to train our data on and then test its performance against the test data. With all the feature engineering already done in the previous step, applying machine learning should be fairly concise.\n",
    "\n",
    "#### Model Selection\n",
    "We need to however come up with a classifier that performs the best, given the features. In such competitions, Ensemble Methods give the best results. We will train our model using two classifiers: Logistic Regression and Random Forest and \n",
    "choose the one with the best accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = LogisticRegression( dual=False, class_weight= 'balanced' , max_iter=1000, multi_class='ovr', \n",
    "#                            verbose=1)\n",
    "# model.fit(train_X,train_y)\n",
    "# print(\"Score: \" + str(model.score(test_X, test_y)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   42.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    2.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.6030395592451698\n",
      "Score: 0.5834754417855068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda_20200421\\envs\\myenv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   18.1s finished\n"
     ]
    }
   ],
   "source": [
    "\n",
    "classifiers = [RandomForestClassifier( verbose=1), \n",
    "               LogisticRegression(verbose=1)]\n",
    "\n",
    "for classifier in classifiers:\n",
    "    classifier.fit(train_X, train_y)\n",
    "    print(\"Score: \" + str(classifier.score(test_X, test_y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the default hyperparameters RandomForest Classifier performs better than Logistic Classifier. And the magin of differene between these two is very less. However, we will go with the Random Forest model for our final submission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning using Grid Search Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'n_estimators': [100,200],\n",
    "    'max_features': ['auto', 'log2'],\n",
    "    'max_depth': [3,5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[CV] max_depth=3, max_features=auto, n_estimators=100 ................\n",
      "[CV]  max_depth=3, max_features=auto, n_estimators=100, score=0.583, total=   7.7s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    7.6s remaining:    0.0s\n",
      "[CV] max_depth=3, max_features=auto, n_estimators=100 ................\n",
      "[CV]  max_depth=3, max_features=auto, n_estimators=100, score=0.583, total=   7.6s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   15.2s remaining:    0.0s\n",
      "[CV] max_depth=3, max_features=auto, n_estimators=100 ................\n",
      "[CV]  max_depth=3, max_features=auto, n_estimators=100, score=0.583, total=   7.6s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   22.8s remaining:    0.0s\n",
      "[CV] max_depth=3, max_features=auto, n_estimators=100 ................\n",
      "[CV]  max_depth=3, max_features=auto, n_estimators=100, score=0.584, total=   8.1s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   30.9s remaining:    0.0s\n",
      "[CV] max_depth=3, max_features=auto, n_estimators=100 ................\n",
      "[CV]  max_depth=3, max_features=auto, n_estimators=100, score=0.583, total=   6.7s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   37.7s remaining:    0.0s\n",
      "[CV] max_depth=3, max_features=auto, n_estimators=200 ................\n",
      "[CV]  max_depth=3, max_features=auto, n_estimators=200, score=0.583, total=  14.8s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   52.4s remaining:    0.0s\n",
      "[CV] max_depth=3, max_features=auto, n_estimators=200 ................\n",
      "[CV]  max_depth=3, max_features=auto, n_estimators=200, score=0.583, total=  14.1s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:  1.1min remaining:    0.0s\n",
      "[CV] max_depth=3, max_features=auto, n_estimators=200 ................\n",
      "[CV]  max_depth=3, max_features=auto, n_estimators=200, score=0.583, total=  13.7s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:  1.3min remaining:    0.0s\n",
      "[CV] max_depth=3, max_features=auto, n_estimators=200 ................\n",
      "[CV]  max_depth=3, max_features=auto, n_estimators=200, score=0.584, total=  14.8s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:  1.6min remaining:    0.0s\n",
      "[CV] max_depth=3, max_features=auto, n_estimators=200 ................\n",
      "[CV]  max_depth=3, max_features=auto, n_estimators=200, score=0.583, total=  14.4s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:  1.8min remaining:    0.0s\n",
      "[CV] max_depth=3, max_features=log2, n_estimators=100 ................\n",
      "[CV]  max_depth=3, max_features=log2, n_estimators=100, score=0.583, total=   6.9s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:  1.9min remaining:    0.0s\n",
      "[CV] max_depth=3, max_features=log2, n_estimators=100 ................\n",
      "[CV]  max_depth=3, max_features=log2, n_estimators=100, score=0.583, total=   8.2s\n",
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:  2.1min remaining:    0.0s\n",
      "[CV] max_depth=3, max_features=log2, n_estimators=100 ................\n",
      "[CV]  max_depth=3, max_features=log2, n_estimators=100, score=0.583, total=   7.2s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:  2.2min remaining:    0.0s\n",
      "[CV] max_depth=3, max_features=log2, n_estimators=100 ................\n",
      "[CV]  max_depth=3, max_features=log2, n_estimators=100, score=0.584, total=   7.2s\n",
      "[Parallel(n_jobs=1)]: Done  14 out of  14 | elapsed:  2.3min remaining:    0.0s\n",
      "[CV] max_depth=3, max_features=log2, n_estimators=100 ................\n",
      "[CV]  max_depth=3, max_features=log2, n_estimators=100, score=0.583, total=   7.1s\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:  2.4min remaining:    0.0s\n",
      "[CV] max_depth=3, max_features=log2, n_estimators=200 ................\n",
      "[CV]  max_depth=3, max_features=log2, n_estimators=200, score=0.583, total=  14.2s\n",
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:  2.7min remaining:    0.0s\n",
      "[CV] max_depth=3, max_features=log2, n_estimators=200 ................\n",
      "[CV]  max_depth=3, max_features=log2, n_estimators=200, score=0.583, total=  14.8s\n",
      "[Parallel(n_jobs=1)]: Done  17 out of  17 | elapsed:  2.9min remaining:    0.0s\n",
      "[CV] max_depth=3, max_features=log2, n_estimators=200 ................\n",
      "[CV]  max_depth=3, max_features=log2, n_estimators=200, score=0.583, total=  14.1s\n",
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:  3.2min remaining:    0.0s\n",
      "[CV] max_depth=3, max_features=log2, n_estimators=200 ................\n",
      "[CV]  max_depth=3, max_features=log2, n_estimators=200, score=0.584, total=  16.1s\n",
      "[Parallel(n_jobs=1)]: Done  19 out of  19 | elapsed:  3.4min remaining:    0.0s\n",
      "[CV] max_depth=3, max_features=log2, n_estimators=200 ................\n",
      "[CV]  max_depth=3, max_features=log2, n_estimators=200, score=0.583, total=  14.0s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:  3.7min remaining:    0.0s\n",
      "[CV] max_depth=5, max_features=auto, n_estimators=100 ................\n",
      "[CV]  max_depth=5, max_features=auto, n_estimators=100, score=0.590, total=  11.5s\n",
      "[Parallel(n_jobs=1)]: Done  21 out of  21 | elapsed:  3.9min remaining:    0.0s\n",
      "[CV] max_depth=5, max_features=auto, n_estimators=100 ................\n",
      "[CV]  max_depth=5, max_features=auto, n_estimators=100, score=0.590, total=  10.8s\n",
      "[Parallel(n_jobs=1)]: Done  22 out of  22 | elapsed:  4.0min remaining:    0.0s\n",
      "[CV] max_depth=5, max_features=auto, n_estimators=100 ................\n",
      "[CV]  max_depth=5, max_features=auto, n_estimators=100, score=0.589, total=  10.4s\n",
      "[Parallel(n_jobs=1)]: Done  23 out of  23 | elapsed:  4.2min remaining:    0.0s\n",
      "[CV] max_depth=5, max_features=auto, n_estimators=100 ................\n",
      "[CV]  max_depth=5, max_features=auto, n_estimators=100, score=0.589, total=  10.1s\n",
      "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed:  4.4min remaining:    0.0s\n",
      "[CV] max_depth=5, max_features=auto, n_estimators=100 ................\n",
      "[CV]  max_depth=5, max_features=auto, n_estimators=100, score=0.591, total=  11.4s\n",
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:  4.6min remaining:    0.0s\n",
      "[CV] max_depth=5, max_features=auto, n_estimators=200 ................\n",
      "[CV]  max_depth=5, max_features=auto, n_estimators=200, score=0.589, total=  24.8s\n",
      "[Parallel(n_jobs=1)]: Done  26 out of  26 | elapsed:  5.0min remaining:    0.0s\n",
      "[CV] max_depth=5, max_features=auto, n_estimators=200 ................\n",
      "[CV]  max_depth=5, max_features=auto, n_estimators=200, score=0.590, total=  22.3s\n",
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:  5.3min remaining:    0.0s\n",
      "[CV] max_depth=5, max_features=auto, n_estimators=200 ................\n",
      "[CV]  max_depth=5, max_features=auto, n_estimators=200, score=0.589, total=  21.8s\n",
      "[Parallel(n_jobs=1)]: Done  28 out of  28 | elapsed:  5.7min remaining:    0.0s\n",
      "[CV] max_depth=5, max_features=auto, n_estimators=200 ................\n",
      "[CV]  max_depth=5, max_features=auto, n_estimators=200, score=0.589, total=  21.4s\n",
      "[Parallel(n_jobs=1)]: Done  29 out of  29 | elapsed:  6.1min remaining:    0.0s\n",
      "[CV] max_depth=5, max_features=auto, n_estimators=200 ................\n",
      "[CV]  max_depth=5, max_features=auto, n_estimators=200, score=0.591, total=  22.2s\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  6.4min remaining:    0.0s\n",
      "[CV] max_depth=5, max_features=log2, n_estimators=100 ................\n",
      "[CV]  max_depth=5, max_features=log2, n_estimators=100, score=0.588, total=  11.4s\n",
      "[Parallel(n_jobs=1)]: Done  31 out of  31 | elapsed:  6.6min remaining:    0.0s\n",
      "[CV] max_depth=5, max_features=log2, n_estimators=100 ................\n",
      "[CV]  max_depth=5, max_features=log2, n_estimators=100, score=0.588, total=   8.9s\n",
      "[Parallel(n_jobs=1)]: Done  32 out of  32 | elapsed:  6.8min remaining:    0.0s\n",
      "[CV] max_depth=5, max_features=log2, n_estimators=100 ................\n",
      "[CV]  max_depth=5, max_features=log2, n_estimators=100, score=0.589, total=  10.1s\n",
      "[Parallel(n_jobs=1)]: Done  33 out of  33 | elapsed:  6.9min remaining:    0.0s\n",
      "[CV] max_depth=5, max_features=log2, n_estimators=100 ................\n",
      "[CV]  max_depth=5, max_features=log2, n_estimators=100, score=0.590, total=  10.7s\n",
      "[Parallel(n_jobs=1)]: Done  34 out of  34 | elapsed:  7.1min remaining:    0.0s\n",
      "[CV] max_depth=5, max_features=log2, n_estimators=100 ................\n",
      "[CV]  max_depth=5, max_features=log2, n_estimators=100, score=0.589, total=  10.6s\n",
      "[Parallel(n_jobs=1)]: Done  35 out of  35 | elapsed:  7.3min remaining:    0.0s\n",
      "[CV] max_depth=5, max_features=log2, n_estimators=200 ................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=5, max_features=log2, n_estimators=200, score=0.588, total=  23.0s\n",
      "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed:  7.7min remaining:    0.0s\n",
      "[CV] max_depth=5, max_features=log2, n_estimators=200 ................\n",
      "[CV]  max_depth=5, max_features=log2, n_estimators=200, score=0.588, total=  19.0s\n",
      "[Parallel(n_jobs=1)]: Done  37 out of  37 | elapsed:  8.0min remaining:    0.0s\n",
      "[CV] max_depth=5, max_features=log2, n_estimators=200 ................\n",
      "[CV]  max_depth=5, max_features=log2, n_estimators=200, score=0.588, total=  18.9s\n",
      "[Parallel(n_jobs=1)]: Done  38 out of  38 | elapsed:  8.3min remaining:    0.0s\n",
      "[CV] max_depth=5, max_features=log2, n_estimators=200 ................\n",
      "[CV]  max_depth=5, max_features=log2, n_estimators=200, score=0.588, total=  21.5s\n",
      "[Parallel(n_jobs=1)]: Done  39 out of  39 | elapsed:  8.7min remaining:    0.0s\n",
      "[CV] max_depth=5, max_features=log2, n_estimators=200 ................\n",
      "[CV]  max_depth=5, max_features=log2, n_estimators=200, score=0.588, total=  22.4s\n",
      "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed:  9.0min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed:  9.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=RandomForestClassifier(),\n",
       "             param_grid={'max_depth': [3, 5], 'max_features': ['auto', 'log2'],\n",
       "                         'n_estimators': [100, 200]},\n",
       "             verbose=100)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GridSearchCV(RandomForestClassifier(), parameters, verbose=100)\n",
    "clf.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=5)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   52.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.6033956111912748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    3.5s finished\n"
     ]
    }
   ],
   "source": [
    "classifier = RandomForestClassifier( verbose=1,max_features= 'auto' )\n",
    "\n",
    "classifier.fit(train_X, train_y)\n",
    "print(\"Score: \" + str(classifier.score(test_X, test_y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing and Final Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date_account_created</th>\n",
       "      <th>timestamp_first_active</th>\n",
       "      <th>date_first_booking</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>signup_method</th>\n",
       "      <th>signup_flow</th>\n",
       "      <th>language</th>\n",
       "      <th>affiliate_channel</th>\n",
       "      <th>affiliate_provider</th>\n",
       "      <th>first_affiliate_tracked</th>\n",
       "      <th>signup_app</th>\n",
       "      <th>first_device_type</th>\n",
       "      <th>first_browser</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5uwns89zht</td>\n",
       "      <td>2014-07-01</td>\n",
       "      <td>20140701000006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>35.0</td>\n",
       "      <td>facebook</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>direct</td>\n",
       "      <td>direct</td>\n",
       "      <td>untracked</td>\n",
       "      <td>Moweb</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Mobile Safari</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jtl0dijy2j</td>\n",
       "      <td>2014-07-01</td>\n",
       "      <td>20140701000051</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>direct</td>\n",
       "      <td>direct</td>\n",
       "      <td>untracked</td>\n",
       "      <td>Moweb</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Mobile Safari</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xx0ulgorjt</td>\n",
       "      <td>2014-07-01</td>\n",
       "      <td>20140701000148</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>direct</td>\n",
       "      <td>direct</td>\n",
       "      <td>linked</td>\n",
       "      <td>Web</td>\n",
       "      <td>Windows Desktop</td>\n",
       "      <td>Chrome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6c6puo6ix0</td>\n",
       "      <td>2014-07-01</td>\n",
       "      <td>20140701000215</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>direct</td>\n",
       "      <td>direct</td>\n",
       "      <td>linked</td>\n",
       "      <td>Web</td>\n",
       "      <td>Windows Desktop</td>\n",
       "      <td>IE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>czqhjk3yfe</td>\n",
       "      <td>2014-07-01</td>\n",
       "      <td>20140701000305</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>direct</td>\n",
       "      <td>direct</td>\n",
       "      <td>untracked</td>\n",
       "      <td>Web</td>\n",
       "      <td>Mac Desktop</td>\n",
       "      <td>Safari</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id date_account_created  timestamp_first_active  \\\n",
       "0  5uwns89zht           2014-07-01          20140701000006   \n",
       "1  jtl0dijy2j           2014-07-01          20140701000051   \n",
       "2  xx0ulgorjt           2014-07-01          20140701000148   \n",
       "3  6c6puo6ix0           2014-07-01          20140701000215   \n",
       "4  czqhjk3yfe           2014-07-01          20140701000305   \n",
       "\n",
       "   date_first_booking   gender   age signup_method  signup_flow language  \\\n",
       "0                 NaN   FEMALE  35.0      facebook            0       en   \n",
       "1                 NaN  Unknown   NaN         basic            0       en   \n",
       "2                 NaN  Unknown   NaN         basic            0       en   \n",
       "3                 NaN  Unknown   NaN         basic            0       en   \n",
       "4                 NaN  Unknown   NaN         basic            0       en   \n",
       "\n",
       "  affiliate_channel affiliate_provider first_affiliate_tracked signup_app  \\\n",
       "0            direct             direct               untracked      Moweb   \n",
       "1            direct             direct               untracked      Moweb   \n",
       "2            direct             direct                  linked        Web   \n",
       "3            direct             direct                  linked        Web   \n",
       "4            direct             direct               untracked        Web   \n",
       "\n",
       "  first_device_type  first_browser  \n",
       "0            iPhone  Mobile Safari  \n",
       "1            iPhone  Mobile Safari  \n",
       "2   Windows Desktop         Chrome  \n",
       "3   Windows Desktop             IE  \n",
       "4       Mac Desktop         Safari  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('data/test_users.csv')\n",
    "df_test['gender'] = df_test['gender'].replace('-unknown-', 'Unknown')\n",
    "#df_test=df_test.drop('age',axis=1)\n",
    "id_test = df_test.id\n",
    "df_test.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = feature_engineering(df_test)\n",
    "df_test = df_test.drop('is_weibo', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    3.6s finished\n"
     ]
    }
   ],
   "source": [
    "pred_prob = classifier.predict_proba(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5uwns89zht</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jtl0dijy2j</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xx0ulgorjt</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6c6puo6ix0</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>czqhjk3yfe</th>\n",
       "      <td>0.43</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0     1     2     3     4    5     6     7    8    9    10   11\n",
       "id                                                                            \n",
       "5uwns89zht  0.70  0.14  0.01  0.00  0.00  0.0  0.00  0.15  0.0  0.0  0.00  0.0\n",
       "jtl0dijy2j  0.77  0.23  0.00  0.00  0.00  0.0  0.00  0.00  0.0  0.0  0.00  0.0\n",
       "xx0ulgorjt  0.62  0.30  0.04  0.01  0.00  0.0  0.01  0.02  0.0  0.0  0.00  0.0\n",
       "6c6puo6ix0  0.88  0.05  0.04  0.00  0.00  0.0  0.03  0.00  0.0  0.0  0.00  0.0\n",
       "czqhjk3yfe  0.43  0.13  0.21  0.11  0.03  0.0  0.01  0.07  0.0  0.0  0.01  0.0"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_prob = pd.DataFrame(pred_prob, index=df_test.index)\n",
    "pred_prob.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'NDF',\n",
       " 1: 'US',\n",
       " 2: 'other',\n",
       " 3: 'FR',\n",
       " 4: 'CA',\n",
       " 5: 'GB',\n",
       " 6: 'ES',\n",
       " 7: 'IT',\n",
       " 8: 'PT',\n",
       " 9: 'NL',\n",
       " 10: 'DE',\n",
       " 11: 'AU'}"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "inv_classes = {v: k for k, v in class_dict.items()}\n",
    "inv_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top(s):\n",
    "    indexes = [i for i in range(0,12)]\n",
    "    lst = list(zip(indexes, s))\n",
    "    top_five = sorted(lst, key=lambda x: x[1], reverse=True)[:2]\n",
    "    top_five = [inv_classes[i[0]] for i in top_five]\n",
    "    return str(top_five)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>get_top</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5uwns89zht</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['NDF', 'IT']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jtl0dijy2j</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['NDF', 'US']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xx0ulgorjt</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['NDF', 'US']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6c6puo6ix0</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['NDF', 'US']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>czqhjk3yfe</th>\n",
       "      <td>0.43</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['NDF', 'other']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0     1     2     3     4    5     6     7    8    9    10  \\\n",
       "id                                                                          \n",
       "5uwns89zht  0.70  0.14  0.01  0.00  0.00  0.0  0.00  0.15  0.0  0.0  0.00   \n",
       "jtl0dijy2j  0.77  0.23  0.00  0.00  0.00  0.0  0.00  0.00  0.0  0.0  0.00   \n",
       "xx0ulgorjt  0.62  0.30  0.04  0.01  0.00  0.0  0.01  0.02  0.0  0.0  0.00   \n",
       "6c6puo6ix0  0.88  0.05  0.04  0.00  0.00  0.0  0.03  0.00  0.0  0.0  0.00   \n",
       "czqhjk3yfe  0.43  0.13  0.21  0.11  0.03  0.0  0.01  0.07  0.0  0.0  0.01   \n",
       "\n",
       "             11           get_top  \n",
       "id                                 \n",
       "5uwns89zht  0.0     ['NDF', 'IT']  \n",
       "jtl0dijy2j  0.0     ['NDF', 'US']  \n",
       "xx0ulgorjt  0.0     ['NDF', 'US']  \n",
       "6c6puo6ix0  0.0     ['NDF', 'US']  \n",
       "czqhjk3yfe  0.0  ['NDF', 'other']  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_prob['get_top'] = pred_prob.apply(get_top, axis=1)\n",
    "pred_prob.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "pred_prob['get_top'] = pred_prob['get_top'].apply(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pred_prob.apply(lambda x: pd.Series(x['get_top']),axis=1).stack().reset_index(level=1, drop=True)\n",
    "s.name = 'country'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0010k6l0om</th>\n",
       "      <td>NDF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0010k6l0om</th>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0031awlkjq</th>\n",
       "      <td>NDF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0031awlkjq</th>\n",
       "      <td>FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00378ocvlh</th>\n",
       "      <td>NDF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           country\n",
       "id                \n",
       "0010k6l0om     NDF\n",
       "0010k6l0om      US\n",
       "0031awlkjq     NDF\n",
       "0031awlkjq      FR\n",
       "00378ocvlh     NDF"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pred_prob.drop([i for i in range(0,12)] + ['get_top'], axis=1).join(s)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use SHAP library to explain the used model.\n",
    "Ref : https://towardsdatascience.com/explain-your-model-with-the-shap-values-bc36aac4de3d"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
